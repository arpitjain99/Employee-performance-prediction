{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB-7k02h7tNz",
        "outputId": "30a1cada-0c67-4483-bc57-08f30994ec50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset loaded successfully!\n",
            "‚úÖ Missing values in 'wip' column handled by filling with the mean.\n",
            "‚úÖ 'month' feature created and 'date' column dropped.\n",
            "‚úÖ 'department' column cleaned and standardized.\n",
            "‚úÖ Categorical features converted to numerical using one-hot encoding.\n",
            "\n",
            "üìä Data split into 957 training samples and 240 testing samples.\n",
            "\n",
            "üöÄ Training models...\n",
            "   - Linear Regression trained.\n",
            "   - Random Forest trained.\n",
            "   - XGBoost trained.\n",
            "\n",
            "üìà Evaluating model performance...\n",
            "\n",
            "--- Model Performance Comparison ---\n",
            "            Model      MAE      MSE  R¬≤ Score\n",
            "Linear Regression 0.108824 0.021921  0.174430\n",
            "    Random Forest 0.071849 0.013704  0.483890\n",
            "          XGBoost 0.077149 0.017219  0.351514\n",
            "------------------------------------\n",
            "\n",
            "üèÜ Best performing model is: Random Forest (based on R¬≤ Score)\n",
            "üíæ Best model has been saved to 'best_productivity_model.pkl'.\n",
            "‚úÖ Model successfully loaded for verification.\n"
          ]
        }
      ],
      "source": [
        "# 1. Import Necessary Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "# Ignore warnings for a cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- DATA LOADING AND PREPROCESSING ---\n",
        "\n",
        "# 2. Load the Dataset\n",
        "try:\n",
        "    # Make sure the CSV file is in the same directory or provide the correct path\n",
        "    df = pd.read_csv('garments_worker_productivity.csv')\n",
        "    print(\"‚úÖ Dataset loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: 'garments_worker_productivity.csv' not found.\")\n",
        "    print(\"Please ensure the dataset file is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "# 3. Handle Missing Values\n",
        "# The original notebook dropped 'wip', here we will fill missing values with the mean\n",
        "# This retains the column which might have predictive power.\n",
        "if 'wip' in df.columns and df['wip'].isnull().any():\n",
        "    df['wip'].fillna(df['wip'].mean(), inplace=True)\n",
        "    print(\"‚úÖ Missing values in 'wip' column handled by filling with the mean.\")\n",
        "\n",
        "# 4. Feature Engineering from Date\n",
        "# Convert 'date' column to datetime objects\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "# Create a 'month' feature from the date\n",
        "df['month'] = df['date'].dt.month\n",
        "# Drop the original 'date' column as it's no longer needed\n",
        "df = df.drop(columns=['date'])\n",
        "print(\"‚úÖ 'month' feature created and 'date' column dropped.\")\n",
        "\n",
        "# 5. Clean Categorical Data\n",
        "# Standardize the 'department' column values\n",
        "df['department'] = df['department'].str.strip().str.lower()\n",
        "df['department'] = df['department'].replace({'sweing': 'sewing', 'finishing ': 'finishing'})\n",
        "print(\"‚úÖ 'department' column cleaned and standardized.\")\n",
        "\n",
        "# 6. Handle Categorical Columns with One-Hot Encoding\n",
        "# One-hot encoding is often better than label encoding for nominal categories\n",
        "# as it doesn't imply an ordinal relationship.\n",
        "categorical_cols = ['quarter', 'department', 'day']\n",
        "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "print(\"‚úÖ Categorical features converted to numerical using one-hot encoding.\")\n",
        "\n",
        "\n",
        "# --- MODEL BUILDING AND EVALUATION ---\n",
        "\n",
        "# 7. Splitting Data into Training and Testing Sets\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop('actual_productivity', axis=1)\n",
        "y = df['actual_productivity']\n",
        "\n",
        "# Split the data (80% for training, 20% for testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"\\nüìä Data split into {len(X_train)} training samples and {len(X_test)} testing samples.\")\n",
        "\n",
        "# 8. Initialize and Train Models\n",
        "print(\"\\nüöÄ Training models...\")\n",
        "\n",
        "# a) Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "print(\"   - Linear Regression trained.\")\n",
        "\n",
        "# b) Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"   - Random Forest trained.\")\n",
        "\n",
        "# c) XGBoost Regressor\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"   - XGBoost trained.\")\n",
        "\n",
        "# 9. Evaluate Models\n",
        "print(\"\\nüìà Evaluating model performance...\")\n",
        "models = {\n",
        "    \"Linear Regression\": lr_model,\n",
        "    \"Random Forest\": rf_model,\n",
        "    \"XGBoost\": xgb_model\n",
        "}\n",
        "\n",
        "performance_data = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    predictions = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    performance_data.append({\"Model\": name, \"MAE\": mae, \"MSE\": mse, \"R¬≤ Score\": r2})\n",
        "\n",
        "# Create a DataFrame for a clean comparison table\n",
        "performance_df = pd.DataFrame(performance_data)\n",
        "print(\"\\n--- Model Performance Comparison ---\")\n",
        "print(performance_df.to_string(index=False))\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "\n",
        "# --- SAVE THE BEST MODEL ---\n",
        "\n",
        "# 10. Identify and Save the Best Model based on R¬≤ Score\n",
        "best_model_name = performance_df.loc[performance_df['R¬≤ Score'].idxmax()]['Model']\n",
        "best_model_obj = models[best_model_name]\n",
        "\n",
        "print(f\"\\nüèÜ Best performing model is: {best_model_name} (based on R¬≤ Score)\")\n",
        "\n",
        "# 11. Save the model to a .pkl file\n",
        "model_filename = \"best_productivity_model.pkl\"\n",
        "with open(model_filename, 'wb') as file:\n",
        "    pickle.dump(best_model_obj, file)\n",
        "\n",
        "print(f\"üíæ Best model has been saved to '{model_filename}'.\")\n",
        "\n",
        "# Optional: Verify the model can be loaded\n",
        "try:\n",
        "    loaded_model = pickle.load(open(model_filename, 'rb'))\n",
        "    print(\"‚úÖ Model successfully loaded for verification.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading saved model: {e}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
